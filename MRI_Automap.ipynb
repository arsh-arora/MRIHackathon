{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c5ec90-07df-4542-a653-35bbf214fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Conv2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4803e3-36de-4f40-a5d8-093ab3ac8017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_set14_images(root_dir='Set14'):\n",
    "    subfolders = ['image_SRF_2', 'image_SRF_3', 'image_SRF_4']\n",
    "    images = []\n",
    "    for subfolder in subfolders:\n",
    "        subfolder_path = os.path.join(root_dir, subfolder)\n",
    "        if not os.path.exists(subfolder_path):\n",
    "            print(f\"Subfolder {subfolder_path} does not exist.\")\n",
    "            continue\n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "                img_path = os.path.join(subfolder_path, filename)\n",
    "                img = Image.open(img_path).convert('L')\n",
    "                img = img.resize((128, 128), Image.BICUBIC)\n",
    "                img_array = np.array(img) / 255.0 \n",
    "                images.append(img_array)\n",
    "    images = np.array(images)\n",
    "    print(f\"Loaded {len(images)} images from Set14 dataset.\")\n",
    "    return images\n",
    "\n",
    "images = load_set14_images(root_dir='Set14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2792a815-592c-4d8a-8bc6-b3ea7d452b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_image(images):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(images[0], cmap='gray')\n",
    "    plt.title('Sample Set14 Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_sample_image(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d3bc7-1213-4d18-81f3-3eee41d6105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(images, patch_size=32, stride=16):\n",
    "    patches = []\n",
    "    for img in images:\n",
    "        h, w = img.shape\n",
    "        for i in range(0, h - patch_size + 1, stride):\n",
    "            for j in range(0, w - patch_size + 1, stride):\n",
    "                patch = img[i:i+patch_size, j:j+patch_size]\n",
    "                patches.append(patch)\n",
    "    patches = np.array(patches)\n",
    "    print(f\"Extracted {len(patches)} patches.\")\n",
    "    return patches\n",
    "patches = extract_patches(images, patch_size=32, stride=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f816029b-63c7-4c8a-a2a2-627ab93e222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(images, std_dev):\n",
    "    noise = np.random.normal(0, std_dev, images.shape)\n",
    "    noisy_images = images + noise\n",
    "    noisy_images = np.clip(noisy_images, 0., 1.)\n",
    "    return noisy_images\n",
    "\n",
    "std_dev = 0.1\n",
    "noisy_patches = add_gaussian_noise(patches, std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3020c67b-50a4-4954-ae82-3364131ce676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_space_data(images):\n",
    "    k_space = np.fft.fftshift(np.fft.fft2(images, axes=(-2, -1)))\n",
    "    return k_space\n",
    "\n",
    "k_space_noisy = get_k_space_data(noisy_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac811a6-2504-4b6a-9671-62f718c1c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(k_space_noisy, patches):\n",
    "    k_space_noisy_real = np.real(k_space_noisy)\n",
    "    k_space_noisy_imag = np.imag(k_space_noisy)\n",
    "\n",
    "    n = k_space_noisy_real.shape[1]\n",
    "    X_real_flat = k_space_noisy_real.reshape(-1, n * n)\n",
    "    X_imag_flat = k_space_noisy_imag.reshape(-1, n * n)\n",
    "    X = np.concatenate([X_real_flat, X_imag_flat], axis=1)\n",
    "    y = patches.reshape(-1, n, n, 1)\n",
    "    return X, y\n",
    "\n",
    "X, y = prepare_data(k_space_noisy, patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe4151-db95-4685-9f0d-a1b0fe2d44fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_automap_model(n):\n",
    "    inputs = Input(shape=(2 * n * n,))\n",
    "    x = Dense(8 * n * n, activation='tanh')(inputs)\n",
    "    x = Dense(8 * n * n, activation='tanh')(x)\n",
    "    x = Dense(4 * n * n, activation='tanh')(x)\n",
    "    x = Dense(n * n, activation='tanh')(x)\n",
    "    x = Reshape((n, n, 1))(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "n = patches.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579c311a-adeb-4980-ac14-ede8980986c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_automap_model(n)\n",
    "model.compile(optimizer=Adam(1e-4), loss='mean_squared_error')\n",
    "\n",
    "print(\"AUTOMAP Model with Increased Capacity:\")\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X, y, epochs=50, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faccf8a8-a527-4665-a779-16e7f5259817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(model, X, y, num_samples=5):\n",
    "    indices = random.sample(range(len(X)), num_samples)\n",
    "    for idx in indices:\n",
    "        X_input = X[idx:idx+1]\n",
    "        n = int(np.sqrt(X_input.shape[1] // 2))\n",
    "        reconstructed = model.predict(X_input)[0, :, :, 0]\n",
    "        target = y[idx, :, :, 0]\n",
    "        k_space_noisy_real = X_input[:, :n*n].reshape(n, n)\n",
    "        k_space_noisy_imag = X_input[:, n*n:].reshape(n, n)\n",
    "        k_space_noisy_complex = k_space_noisy_real + 1j * k_space_noisy_imag\n",
    "        noisy_image_complex = np.fft.ifft2(np.fft.ifftshift(k_space_noisy_complex))\n",
    "        noisy_image = np.abs(noisy_image_complex)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title('Noisy Image')\n",
    "        plt.imshow(noisy_image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title('Reconstructed Image')\n",
    "        plt.imshow(reconstructed, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title('Ground Truth')\n",
    "        plt.imshow(target, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "display_results(model, X, y, num_samples=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
